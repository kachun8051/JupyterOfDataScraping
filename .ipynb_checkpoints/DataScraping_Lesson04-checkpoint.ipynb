{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bb6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group() = 2575-2803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "match = re.compile(r'\\d\\d\\d\\d-\\d\\d\\d\\d')\n",
    "ans = match.search('Line1: 2575-2803  Line2: 2575-7933')\n",
    "print('group() =', ans.group())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0fff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2575-2803', '2575-7933']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match = re.compile(r'\\d\\d\\d\\d-\\d\\d\\d\\d')\n",
    "ans = match.findall('Line1: 2575-2803  Line2: 2575-7933')\n",
    "print(ans)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4825728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2575', '2803'), ('2575', '7933')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match = re.compile(r'(\\d\\d\\d\\d)-(\\d\\d\\d\\d)')\n",
    "ans = match.findall('Line1: 2575-2803  Line2: 2575-7933')\n",
    "print(ans)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c739ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 Alex', '8 Ada', '5 Amy', '1 John', '2 Danny', '7 Candy', '3 Mandy', '6 Apple', '12 Orange', '313 Cindy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match = re.compile(r'\\d+\\s\\w+')\n",
    "ans = match.findall('4 Alex, 8 Ada, 5 Amy, 1 John, 2 Danny, 7 Candy, 3 Mandy, 6 Apple, 12 Orange, 313 Cindy')\n",
    "print(ans)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f609b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4': 'Alex', '8': 'Ada', '5': 'Amy', '1': 'John', '2': 'Danny', '7': 'Candy', '3': 'Mandy', '6': 'Apple', '12': 'Orange', '313': 'Cindy'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match = re.compile(r'(\\d+)\\s(\\w+)')\n",
    "ans = match.findall('4 Alex, 8 Ada, 5 Amy, 1 John, 2 Danny, 7 Candy, 3 Mandy, 6 Apple, 12 Orange, 313 Cindy')\n",
    "# print(ans)\n",
    "myDict = dict(ans)\n",
    "print(myDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3747fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Candy', 'Mandy']\n"
     ]
    }
   ],
   "source": [
    "match = re.compile(r'.andy')\n",
    "ans = match.findall('Staff: Ada, Amy, Candy, Cindy, Mandy')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d1360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Candy', 'Mandy', ' andy']\n"
     ]
    }
   ],
   "source": [
    "match = re.compile(r'.andy')\n",
    "ans = match.findall('Staff: Ada, Amy, Candy, Cindy, Mandy, andy')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2bbc41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['2555-0313', '2541-0470', '2519-0123', '2893-3112', '2892-1276', '2508-9200', '2712-9175', '3104-1398', '2568-8922', '2914-4266']\n",
      "Duplicated: ['2519-0123', '2508-9200', '2712-9175', '2712-9175']\n",
      "Copied to File\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read text file\n",
    "with open('.\\\\materials\\\\sample428.txt') as checkFile:\n",
    "    Text = checkFile.read()\n",
    "\n",
    "# Phone Regex\n",
    "phoneRe = re.compile(r'((\\d{4})(\\s|-)*(\\d{4}))')\n",
    "\n",
    "Result = []\n",
    "lstDup = []\n",
    "for groups in phoneRe.findall(Text):\n",
    "    phoneNum = '-'.join([groups[1], groups[3]])\n",
    "    if phoneNum not in Result:\n",
    "        Result.append(phoneNum)\n",
    "    else:\n",
    "        lstDup.append(phoneNum)\n",
    "\n",
    "print('Result: ' + str(Result))\n",
    "print('Duplicated: ' + str(lstDup))\n",
    "        \n",
    "# Copy Result to New File\n",
    "if len(Result) > 0:\n",
    "    # convert into set to eliminate duplicated items\n",
    "    # Result = set(Result)\n",
    "    with open('.\\\\output\\\\Result.txt','w') as resultFile:\n",
    "        resultFile.write('\\n'.join(Result))\n",
    "    print('Copied to File')\n",
    "else:\n",
    "    print('No phone found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6960c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a951f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da1414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (4.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a82c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<img alt=\"\" src=\"images/sample113a.jpg\"/>\n",
      "<blockquote class=\"remark\">We have been working towards these goals for the last <strong>19 years</strong>. We shall\r\n",
      "    continue to achieve further. Zaxime magnam ad assumenda saepe, exercitationem doloremque deserunt cumque excepturi\r\n",
      "    quam commodi odit, repellat molestiae laudantium quae libero tenetur voluptatem delectus ut suscipit. Nulla impedit\r\n",
      "    deserunt iste consectetur. Consectetur qui autem iure quibusdam maxime ab omnis et doloremque, asperiores eligendi\r\n",
      "    ipsam dignissimos.</blockquote>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://goodview.125mb.com'\n",
    "html = requests.get(url)\n",
    "html.encoding = 'UTF-8'\n",
    "\n",
    "#bs = BeautifulSoup(html.text, 'html.parser')\n",
    "bs = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "print(type(bs))\n",
    "\n",
    "# print(bs.h1)\n",
    "# print(bs.p)\n",
    "# print(bs.strong)\n",
    "# print(bs.strong.text)\n",
    "\n",
    "print(bs.img)\n",
    "print(bs.blockquote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c27734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"yellow\" id=\"lemon\">We believe that students can achieve the most <a class=\"remark\" href=\"https://www.ftustsc.org.hk/\">value-added\n",
      "      service</a> through our practical approach. We work with competent partners to synergies our knowledge and\n",
      "    expertise so as to provide the best training to our students. As Marks Spencer has expressed that the <strong>best\n",
      "      media</strong> of promotion is by the mouth of the customers. We aim to provide quality training and we rely on\n",
      "    our studentsâ€™ loyalty to warrant our growth.</p>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('.\\\\materials\\\\demopage2.html', encoding=\"utf-8\") as html:\n",
    "    sp = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "# print(sp.find('p'))\n",
    "# print(sp.find_all('p'))\n",
    "# print()\n",
    "\n",
    "print(sp.find('p', id='lemon', class_='yellow'))\n",
    "print(sp.find('p', {'id':'banana', 'class':'yellow'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b97fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 id=\"title\">Welcome to GoodView Whiz Club</h1>]\n",
      "<h1 id=\"title\">Welcome to GoodView Whiz Club</h1>\n",
      "h1\n",
      "{'id': 'title'}\n",
      "Welcome to GoodView Whiz Club\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[<strong>Whiz Club Limited</strong>, <strong>computer training</strong>, <strong>best\n",
      "      media</strong>, <strong>19 years</strong>, <strong>aspernatur\n",
      "      cupiditate</strong>]\n",
      "<class 'bs4.element.ResultSet'>\n",
      "5\n",
      "<class 'bs4.element.Tag'>\n",
      "<strong>Whiz Club Limited</strong>\n",
      "strong\n",
      "{}\n",
      "Whiz Club Limited\n",
      "<strong>computer training</strong>\n",
      "computer training\n",
      "None\n",
      "<strong>best\n",
      "      media</strong>\n",
      "best\n",
      "      media\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "<a class=\"remark\" href=\"https://www.ftustsc.org.hk/\">value-added\n",
      "      service</a>\n",
      "None\n",
      "['remark']\n",
      "{'class': ['remark'], 'href': 'https://www.ftustsc.org.hk/'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('.\\\\materials\\\\demopage2.html', encoding=\"utf-8\") as html:\n",
    "    sp = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "elems = sp.select('#title')\n",
    "if len(elems) == 0:\n",
    "    print('No such element')\n",
    "else:\n",
    "    print(elems)\n",
    "    print(elems[0]) \n",
    "    print(elems[0].name)\n",
    "    print(elems[0].attrs)\n",
    "    print(elems[0].getText())\n",
    "    print('~' * 40)\n",
    "\n",
    "elems = sp.select('strong')\n",
    "print(elems)\n",
    "print(type(elems))\n",
    "print(len(elems))\n",
    "\n",
    "print(type(elems[0]))\n",
    "print(elems[0]) \n",
    "print(elems[0].name) \n",
    "print(elems[0].attrs)\n",
    "print(elems[0].getText()) \n",
    "\n",
    "print(elems[1])\n",
    "print(elems[1].getText())\n",
    "print(elems[1].get('class'))\n",
    "\n",
    "print(elems[2])\n",
    "print(elems[2].getText())\n",
    "print('~' * 40)\n",
    "\n",
    "elems = sp.select('.remark')[0]\n",
    "print(elems)\n",
    "print(elems.get('id'))\n",
    "print(elems.get('class'))\n",
    "print(elems.attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7000a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such element\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('.\\\\materials\\\\demopage2.html',encoding=\"utf-8\") as html:\n",
    "    sp = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "elems = sp.select('#strong')\n",
    "if len(elems) == 0:\n",
    "    print('No such element')\n",
    "else:\n",
    "    for elem in elems:\n",
    "        print(elem)\n",
    "        #print(elem[0]) \n",
    "        print(elem.name)\n",
    "        print(elem.attrs)\n",
    "        print(elem.getText())\n",
    "        print('~' * 40)\n",
    "\n",
    "# elems = sp.select('strong')\n",
    "# print(elems)\n",
    "# print(type(elems))\n",
    "# print(len(elems))\n",
    "\n",
    "# print(type(elems[0]))\n",
    "# print(elems[0]) \n",
    "# print(elems[0].name) \n",
    "# print(elems[0].attrs)\n",
    "# print(elems[0].getText()) \n",
    "\n",
    "# print(elems[1])\n",
    "# print(elems[1].getText())\n",
    "# print(elems[1].get('class'))\n",
    "\n",
    "# print(elems[2])\n",
    "# print(elems[2].getText())\n",
    "# print('~' * 40)\n",
    "\n",
    "# elems = sp.select('.remark')[0]\n",
    "# print(elems)\n",
    "# print(elems.get('id'))\n",
    "# print(elems.get('class'))\n",
    "# print(elems.attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c218692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: http://goodview.125mb.com\n"
     ]
    }
   ],
   "source": [
    "# Sample 433\n",
    "import os\n",
    "\n",
    "myUrl = 'http://goodview.125mb.com/photostyle.html'\n",
    "\n",
    "def getDomain(_url):\n",
    "    # url = 'http://goodview.125mb.com/photostyle.html'\n",
    "    _path = os.path.dirname(_url)\n",
    "    return _path\n",
    "\n",
    "path = getDomain(myUrl)\n",
    "print(f'Domain: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708fe8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getImg(_url):\n",
    "    html = requests.get(_url)\n",
    "    html.encoding = 'UTF-8'\n",
    "    sp = BeautifulSoup(html.text, 'html.parser')\n",
    "    elems = sp.select('img')\n",
    "    # print(type(elems))\n",
    "    return elems\n",
    "\n",
    "lstElem = getImg(myUrl)\n",
    "print(f'Length: {len(lstElem)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bb8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgName(_url):\n",
    "    lst1 = _url.split('/')\n",
    "    if len(lst1) == 0:\n",
    "        return lst1[0]\n",
    "    else:\n",
    "        return lst1[len(lst1)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7434a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def checkfolder(_folder):\n",
    "    if not os.path.exists(_folder):\n",
    "        try:\n",
    "            os.makedirs(_folder)\n",
    "            return True\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            return False\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b547c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "def downloadImg(url, imgPath):\n",
    "    _domain = getDomain(url)\n",
    "    _headers = {'Referer': _domain}    \n",
    "    _imgFile = getImgName(imgPath)\n",
    "    _imgLocalPath = 'C:\\\\Temp\\\\img01'\n",
    "    isChecked = checkfolder(_imgLocalPath)\n",
    "    if isChecked == True:\n",
    "        res = requests.get(f'{_domain}/{imgPath}', headers=_headers)\n",
    "        with open(f'{_imgLocalPath}\\\\{_imgFile}', 'wb') as myFile:\n",
    "            for x in res.iter_content(10240):\n",
    "                print(myFile.write(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7ebe4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "\n",
    "def downloadImg2(url, imgPath):\n",
    "    _domain = getDomain(url)\n",
    "    _headers = {'Referer': _domain}\n",
    "    _imgFile = getImgName(imgPath)\n",
    "    _imgLocalPath = 'C:\\\\Temp\\\\img02'\n",
    "    checkfolder(_imgLocalPath)\n",
    "    res = requests.get(f'{_domain}/{imgPath}', stream=True, headers=_headers)\n",
    "    if res.status_code == requests.codes.ok:           \n",
    "        with open(f'{_imgLocalPath}\\\\{_imgFile}', 'wb') as f:\n",
    "            shutil.copyfileobj(res.raw, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the functions\n",
    "getImg(myUrl)\n",
    "for x in lstElem:\n",
    "    print(x.get('src'))\n",
    "    downloadImg(myUrl, x.get('src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63fded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
